---
title: Opciones de Procesamiento
description: Aprende sobre los parámetros que puedes usar con Aryn DocParse
icon: map
---

Hay varias opciones que puedes especificar al llamar a DocParse. Por ejemplo, podemos extraer la estructura de tabla de nuestro documento con el siguiente comando curl.

```bash
export ARYN_API_KEY="PUT API KEY HERE"
    curl -s -N -D headers "https://api.aryn.cloud/v1/document/partition" -H "Authorization: Bearer $ARYN_API_KEY" -F "file=@document.pdf" -F 'options={"extract_table_structure": true}' | tee document.json
```

Todas las opciones disponibles se enumeran a continuación, y son opcionales a menos que se especifique lo contrario.

* `use_ocr`: Un valor booleano que, cuando se establece en `True`, hace que DocParse extraiga texto usando un modelo OCR. Esto es útil cuando el texto no es directamente extraíble del PDF, como cuando el texto es parte de una imagen o cuando el texto está rotado. Cuando se establece en `False`, DocParse extrae texto incrustado del documento de entrada. El valor predeterminado es `False`.

* `text_extraction_options`: Un mapa con claves de cadena que especifica opciones para la extracción de texto.
  * `ocr_text_mode`: Una cadena que especifica el modo a usar para la extracción de texto OCR. El valor predeterminado es `standard`, que usa el pipeline OCR clásico convencional para procesar documentos. La otra opción es `vision`, que usa un modelo de visión para OCR. Ten en cuenta que `vision` solo está disponible para elementos que no son tablas (`standard` se usará para elementos de tabla) y solo para usuarios PAYG.

* `extract_table_structure`: Un booleano que, cuando es `True`, permite que DocParse extraiga tablas y su contenido estructural usando un modelo de extracción de tablas específico. Si se establece en `False`, las tablas aún se identifican pero no se analizan por su estructura; como resultado, las celdas de la tabla y sus cuadros delimitadores no se incluyen en la respuesta. El valor predeterminado es `False`.

* `add_to_docset_id`: Una cadena que especifica el ID del DocSet para almacenar tu documento analizado. Por defecto, DocParse usará el DocSet llamado `docparse_storage` a menos que hayas deshabilitado la retención de datos.

* `table_extraction_options`: Un mapa con claves de cadena que especifica opciones para la extracción de tablas. Solo se aplica cuando `extract_table_structure` es `True`. El valor predeterminado es vacío (`{}`)
  * `include_additional_text`: Booleano. Cuando es `True`, DocParse intentará mejorar la estructura de la tabla fusionando tokens de la extracción de texto. Esto puede ser útil para trabajar con tablas que tienen texto faltante o mal alineado. El valor predeterminado es `False`
  * `model_selection`: Cadena. Una expresión para instruir a DocParse sobre cómo seleccionar el modelo de tabla a usar para la extracción. El valor predeterminado es `"pixels > 500 -> deformable_detr; table_transformer"`, que significa "si la dimensión más grande de la tabla es más de 500 píxeles, usa deformable\_detr; de lo contrario, usa table\_transformer." Para usar solo deformable\_detr o table\_transformer, establece `model_selection="deformable_detr"` o `model_selection="table_transformer"`. Las expresiones de selección tienen la forma

    ```
    metric cmp threshold -> model; metric cmp threshold -> model; model
    ```

    Y deben leerse como una serie de `if metric compares to threshold, then use model`. Las declaraciones se procesan de izquierda a derecha.

    * Los modelos soportados son `table_transformer`, que tiende a funcionar bien con tablas más pequeñas, y `deformable_detr`, que tiende a funcionar mejor con tablas más grandes.
    * Las métricas soportadas son `pixels`, que corresponde a la dimensión máxima del cuadro delimitador que contiene la tabla (encontramos que esto es más fácil de razonar que el número total de píxeles que depende de dos números), y `chars`, que corresponde al número total de caracteres dentro de la tabla según lo determinado por el paso de OCR/extracción de texto.
    * Los umbrales deben ser numéricos.
    * Los operadores de comparación soportados son `<, >, <=, >=, ==, !=`.

    Una declaración sin métrica, comparación y umbral puede considerarse como predeterminada, donde las declaraciones después de la predeterminada no se procesarán. Si no se incluye tal declaración 'incondicional' y no coincide ninguna condición, DocParse usará por defecto table\_transformer. Cualquier cosa después de la declaración incondicional no será procesada.
    Ejemplos:

    * `table_transformer` => siempre usar table transformer
    * `pixels > 500 -> deformable_detr; table_transformer` => si la dimensión más grande de la tabla es mayor que 500 píxeles, usar deformable detr. De lo contrario, usar table\_transformer.
    * `pixels>50->table_transformer; chars<30->deformable_detr;chars>35->table_transformer;pixels>2->deformable_detr;table_transformer;comment` => si la dimensión más grande es más de 50 píxeles usar table transformer. Si no, si el número total de caracteres en la tabla es menor que 30 usar deformable\_detr. Si no, si hay más de 35 caracteres usar table transformer. Si no, si hay más de 2 píxeles en la dimensión más grande usar deformable detr. De lo contrario usar table transformer. el comentario no se procesa.

* `extract_images`: Un booleano que determina si se extraen imágenes del documento. El formato está determinado por el valor de `extract_image_format`. Predeterminado: `False`.

* `extract_image_format`: Una cadena que indica en qué formato deben devolverse las imágenes extraídas. Debe ser uno de `ppm`, `png`, o `jpeg`. En todos los casos, el resultado será codificado en base64 antes de ser devuelto. Predeterminado: `ppm`.

* `summarize_images`: (Solo PAYG) Un booleano que, cuando es `True`, genera un resumen de las imágenes en el documento y lo devuelve como el `text_representation`. Cuando es `False`, las imágenes no se resumen. El valor predeterminado es `False`.

* `ocr_language`: Una cadena que especifica el idioma a usar para OCR. El valor predeterminado es `english` (Inglés). La lista completa de idiomas soportados se puede encontrar [aquí](./formats_supported).

* `selected_pages`: Una lista que especifica páginas individuales (indexadas desde 1) y rangos de páginas del documento a particionar. Las páginas individuales se especifican como enteros y los rangos se especifican como listas con dos entradas enteras en orden ascendente. Un ejemplo válido de valor para selected\_pages es `[1, 10, [15, 20]]` que incluiría las páginas 1, 10, 15, 16, 17 ..., 20.  `selected_pages` es `None` por defecto, lo que resulta en que todas las páginas del documento sean analizadas.

* `chunking_options`: Un diccionario de opciones para especificar el comportamiento de fragmentación. La fragmentación solo se realiza cuando esta opción está presente, y se eligen opciones predeterminadas cuando `chunking_options` se especifica como `{}`.
  * `strategy`: Una cadena que especifica la estrategia a usar para combinar y dividir fragmentos. Los valores válidos son `context_rich` y `maximize_within_limit`. El fragmentador predeterminado y recomendado es `context_rich` como `{'strategy': 'context_rich'}`.
    * Comportamiento del fragmentador `context_rich`: El objetivo de esta estrategia es añadir contexto a fragmentos de tamaño uniforme. Esto es más útil para aplicaciones GenAI basadas en recuperación. La fragmentación context\_rich combina elementos adyacentes `Section-header` y `Title` en un nuevo elemento `Section-header`. Combina elementos en un fragmento con su más reciente `Section-header`. Si el fragmento contendría demasiados tokens, comienza un nuevo fragmento copiando el encabezado de sección al inicio de este nuevo fragmento y continúa. El fragmentador combina elementos en diferentes páginas, a menos que `merge_across_pages` esté configurado como `False`.

    * Comportamiento del fragmentador `maximize_within_limit`: El objetivo del fragmentador `maximize_within_limit` es hacer los fragmentos tan grandes como sea posible. Combina elementos en el conjunto más reciente de elementos combinados a menos que hacerlo haga que su conteo de tokens exceda `max_tokens`. En ese caso, mantendría el nuevo elemento separado y comenzaría a combinar elementos subsiguientes en ese, siguiendo la misma regla. Combina elementos en diferentes páginas, a menos que `merge_across_pages` esté configurado como `False`.
  * `max_tokens`: Un entero que especifica el límite para dividir fragmentos que son demasiado grandes. El valor predeterminado es 512.
  * `tokenizer`: Una cadena que especifica el tokenizador a usar cuando se determina cómo se agrupan los caracteres en un fragmento. Los valores válidos son `openai_tokenizer`, `character_tokenizer`, y `huggingface_tokenizer`. El valor predeterminado es `openai_tokenizer`.
  * `tokenizer_options`: Un árbol con claves de cadena que especifica las opciones para el tokenizador elegido. El valor predeterminado es `{'model_name': 'text-embedding-3-small'}`, que funciona con el tokenizador de OpenAI.
    * Opciones disponibles para `openai_tokenizer`:
      * `model_name`: Acepta todos los modelos soportados por el [tokenizador tiktoken](https://github.com/openai/tiktoken) de OpenAI. El valor predeterminado es "text-embedding-3-small"
    * Opciones disponibles para `HuggingFaceTokenizer`:
      * `model_name`: Acepta todos los tokenizadores de huggingface del [huggingface/tokenizers repo](https://github.com/huggingface/tokenizers).
    * `character_tokenizer` no acepta ninguna opción.
  * `merge_across_pages`: Un `boolean` que cuando `True` el chunker seleccionado intentará fusionar fragmentos a través de los límites de página. El valor predeterminado es `True`.

* `output_format`: Una cadena que controla la representación de salida. El valor predeterminado es `json` que produce un array llamado `elements` que contiene los elementos particionados, representados en JSON. Si se establece en `markdown` la respuesta del servicio incluirá en su lugar un campo llamado `markdown` que contiene una cadena que representa todo el documento en formato Markdown.

* `threshold`: Esto representa el umbral para aceptar los cuadros delimitadores predichos por el modelo. El valor predeterminado es `auto`, donde el servicio utiliza un método de procesamiento para encontrar la mejor predicción para cada posible cuadro delimitador. Esta es la configuración recomendada. Sin embargo, esto puede ser anulado especificando un umbral numérico entre 0 y 1. Si especifica un umbral numérico, solo se devolverán los cuadros delimitadores con puntajes de confianza superiores al umbral (en lugar de usar el método de procesamiento descrito anteriormente). Un valor más bajo incluirá más objetos, pero puede tener superposiciones, mientras que un valor más alto reducirá el número de superposiciones, pero puede perder objetos legítimos. Si establece el umbral manualmente, recomendamos comenzar con un valor de `0.32`.
  Ya sea el específico `string` `auto` o un `float` entre `0.0` y `1.0`, inclusive. Este valor especifica el límite para detectar cuadros delimitadores. Un valor más bajo incluirá más objetos, pero puede tener superposiciones, mientras que un valor más alto reducirá el número de superposiciones, pero puede perder objetos legítimos. El valor predeterminado es `auto` (DocParse elegirá los cuadros delimitadores óptimos).

* `pages_per_call`: Esto solo está disponible cuando se usa la función Partition en Sycamore. Esta opción divide el procesamiento de su documento en lotes de páginas, y usted especifica el tamaño de cada lote (número de páginas). Esto es útil cuando se ejecuta OCR en documentos grandes.

* `output_label_options`: Un diccionario de opciones para especificar qué heurística aplicar para forzar ciertas salidas de etiquetas. Si no se especifica esta opción, no se aplica ninguna heurística. Las opciones que admite el diccionario se enumeran a continuación.
  * `promote_title`: Un booleano que especifica si promover un elemento a título si no hay título en la salida.
  * `title_candidate_elements`: Una lista de cadenas que son elementos candidatos para ser promovidos a título.
  * `orientation_correction`: Un valor booleano que especifica si corregir la orientación de las páginas rotadas durante el paso de preprocesamiento.

* `markdown_options`: Un diccionario de opciones para especificar qué incluir en la salida markdown.
  * `include_pagenum`: Un booleano que especifica si incluir números de página en la salida markdown. El valor predeterminado es `False`.
  * `include_headers`: Un booleano que especifica si incluir encabezados en la salida markdown. El valor predeterminado es `False`.
  * `include_footers`: Un booleano que especifica si incluir pies de página en la salida markdown. El valor predeterminado es `False`.

Aquí hay un ejemplo de cómo puede usar algunas de estas opciones en un comando curl o en código Python con el [Aryn SDK](./aryn_sdk).

<CodeGroup>
  ```bash curl
  export ARYN_API_KEY="PUT API KEY HERE"
  curl -s -N -D headers "https://api.aryn.cloud/v1/document/partition" -H "Authorization: Bearer $ARYN_API_KEY" -F "file=@document.pdf" -F 'options={"use_ocr": true, "extract_table_structure": true, "threshold": 0.2}' | tee document.json
  ```

  ```python aryn_sdk.py
  import os
  import json
  from aryn_sdk.partition import partition_file
  os.environ["ARYN_API_KEY"] = "PUT API KEY HERE"
  with open("document.pdf", "rb") as f:
      ans = partition_file(
          file=f,
          use_ocr=True,
          extract_table_structure=True,
          threshold=0.2
      )
  with open("document.json", "w") as f:
      json.dump(ans, f)
  ```
</CodeGroup>
