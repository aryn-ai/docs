---
- title: Opciones de Procesamiento
- description: Aprenda sobre los parámetros que puede usar con Aryn DocParse
- icon: map
---

Hay varias opciones que puede especificar al llamar a DocParse. Por ejemplo, podemos extraer la estructura de la tabla de nuestro documento con el siguiente comando curl.

```bash
export ARYN_API_KEY="PUT API KEY HERE"
    curl -s -N -D headers "https://api.aryn.cloud/v1/document/partition" -H "Authorization: Bearer $ARYN_API_KEY" -F "file=@document.pdf" -F 'options={"extract_table_structure": true}' | tee document.json
```

Todas las opciones disponibles se enumeran a continuación y son opcionales a menos que se especifique lo contrario.

* `extract_table_structure`: Un booleano que, cuando`True`, permite a DocParse extraer tablas y su contenido estructural utilizando un modelo de extracción de tablas diseñado específicamente. Si se establece en`False`, las tablas aún se identifican pero no se analizan en cuanto a su estructura; como resultado, las celdas de la tabla y sus cuadros delimitadores no se incluyen en la respuesta. El valor predeterminado es`False`.
* `add_to_docset_id`: Una cadena que especifica el ID del DocSet para almacenar su documento analizado. Por defecto, DocParse utilizará el DocSet llamado`docparse_storage` a menos que haya desactivado la retención de datos.
* `extract_images`: Un booleano que determina si se extraen imágenes del documento. El formato se determina por el valor de`extract_image_format`. Predeterminado:`False`.
* `extract_image_format`: Una cadena que indica en qué formato se deben devolver las imágenes extraídas. Debe ser uno de`ppm`,`png`, o`jpeg`. En todos los casos, el resultado se codificará en base64 antes de ser devuelto. Predeterminado:`ppm`.
* `summarize_images`: (Solo PAYG) Un booleano que, cuando`True`, genera un resumen de las imágenes en el documento y lo devuelve como el`text_representation`. Cuando`False`, las imágenes no se resumen. El valor predeterminado es`False`.
* `ocr_language`: Una cadena que especifica el idioma a utilizar para OCR. El valor predeterminado es`english` (inglés). La lista completa de idiomas soportados se puede encontrar[here](./formats_supported).
* `selected_pages`: Una lista que especifica páginas individuales (indexadas desde 1) y rangos de páginas del documento para particionar. Las páginas individuales se especifican como enteros y los rangos se especifican como listas con dos entradas enteras en orden ascendente. Un ejemplo válido de valor para selected\_pages es`[1, 10, [15, 20]]` que incluiría las páginas 1, 10, 15, 16, 17 ..., 20.`selected_pages` es`None` por defecto, lo que resulta en que todas las páginas del documento sean analizadas.
* `table_extraction_options`: Un mapa con claves de cadena que especifica opciones para la extracción de tablas. Solo se aplica cuando`extract_table_structure` es`True`. El valor predeterminado está vacío (`{}`)
  * `include_additional_text`: Booleano. Cuando`True`, DocParse intentará mejorar la estructura de la tabla fusionando tokens de la extracción de texto. Esto puede ser útil para trabajar con tablas que tienen texto faltante o mal alineado. El valor predeterminado es`False`
  * `model_selection`: Cadena. Una expresión para instruir a DocParse sobre cómo seleccionar el modelo de tabla a utilizar para la extracción. El valor predeterminado es`"pixels > 500 -> deformable_detr; table_transformer"`, lo que significa "si la dimensión más grande de la tabla es más de 500 píxeles, use deformable\_detr; de lo contrario, use table\_transformer." Para usar solo deformable\_detr o table\_transformer, establezca`model_selection="deformable_detr"` o`model_selection="table_transformer"`. Las expresiones de selección tienen la forma

    ```
    metric cmp threshold -> model; metric cmp threshold -> model; model
    ```

    Y deben leerse como una serie de`if metric compares to threshold, then use model` declaraciones. Las declaraciones se procesan de izquierda a derecha.

    * Los modelos soportados son`table_transformer`, que tiende a funcionar bien con tablas más pequeñas, y`deformable_detr`, que tiende a funcionar mejor con tablas más grandes.
    * Las métricas soportadas son`pixels`, que corresponde a la dimensión máxima del cuadro delimitador que contiene la tabla (encontramos que esto es más fácil de razonar que el número total de píxeles que depende de dos números), y`chars`, que corresponde al número total de caracteres dentro de la tabla según lo determinado por el paso de OCR/extracción de texto.
    * Los umbrales deben ser numéricos.
    * Los operadores de comparación soportados son`<, >, <=, >=, ==, !=`.

    Una declaración sin métrica, comparación y umbral puede considerarse como predeterminada, donde las declaraciones después de la predeterminada no se procesarán. Si no se incluye tal declaración 'incondicional' y no coincide ninguna condición, DocParse utilizará por defecto table\_transformer. Cualquier cosa después de la declaración incondicional no será procesada.
    Ejemplos:

    * `table_transformer` => siempre usar table transformer
    * `pixels > 500 -> deformable_detr; table_transformer` => si la dimensión más grande de la tabla es mayor que 500 píxeles, usar deformable detr. De lo contrario, usar table\_transformer.
    * `pixels>50->table_transformer; chars<30->deformable_detr;chars>35->table_transformer;pixels>2->deformable_detr;table_transformer;comment` => si la dimensión más grande es más de 50 píxeles, usar table transformer. De lo contrario, si el número total de caracteres en la tabla es menor que 30, usar deformable\_detr. De lo contrario, si hay más de 35 caracteres, usar table transformer. De lo contrario, si hay más de 2 píxeles en la dimensión más grande, usar deformable detr. De lo contrario, usar table transformer. El comentario no se procesa.
* `text_mode`: Una cadena que especifica el modo a utilizar para la extracción de texto. El valor predeterminado es`standard`, que extrae el texto incrustado. Las otras opciones son`fine_grained`, que extrae el texto incrustado de una manera más detallada,`standard_ocr` que utiliza el pipeline clásico de OCR, y`vision_ocr` que utiliza un modelo de visión para OCR.
  Tenga en cuenta que`vision_ocr` está disponible solo para usuarios PAYG.
* `text_extraction_options`: Un mapa con claves de cadena que especifica opciones para la extracción de texto.
  * `ocr_text_mode` (obsoleto): Una cadena que especifica el modo a utilizar para la extracción de texto OCR. El valor predeterminado es`standard`, que utiliza el pipeline convencional de OCR clásico para procesar documentos. La otra opción es`vision`, que utiliza un modelo de visión para OCR. Tenga en cuenta que`vision` está disponible solo para usuarios PAYG.
  * `remove_line_breaks`: Un booleano que especifica si se deben eliminar los saltos de línea del texto. El valor predeterminado es`False`.
* `chunking_options`: Un diccionario de opciones para especificar el comportamiento de fragmentación. La fragmentación solo se realiza cuando esta opción está presente, y se eligen opciones predeterminadas cuando`chunking_options` se especifica como`{}`.
  * `strategy`: Una cadena que especifica la estrategia a utilizar para combinar y dividir fragmentos. Los valores válidos son`context_rich` y`maximize_within_limit`. El fragmentador predeterminado y recomendado es`context_rich` como`{'strategy': 'context_rich'}`.
    * Comportamiento de`context_rich` chunker: The goal of this strategy is to add context to evenly-sized chunks. This is most useful for retrieval based GenAI applications. The context\_rich chunking combines adjacent `Section-header` y`Title` elementos en un nuevo`Section-header` elemento. Fusiona elementos en un fragmento con su más reciente`Section-header`. Si el fragmento contendría demasiados tokens, comienza un nuevo fragmento copiando el encabezado de sección al inicio de este nuevo fragmento y continúa. El fragmentador fusiona elementos en diferentes páginas, a menos que`merge_across_pages` se establezca en`False`.

    * Comportamiento del`maximize_within_limit` chunker: The goal of the `maximize_within_limit` fragmentador es hacer los fragmentos tan grandes como sea posible. Fusiona elementos en el conjunto de elementos fusionados más recientemente a menos que hacerlo haga que su recuento de tokens exceda`max_tokens`. En ese caso, mantendría el nuevo elemento separado y comenzaría a fusionar los elementos subsiguientes en ese, siguiendo la misma regla. Fusiona elementos en diferentes páginas, a menos que`merge_across_pages` se establezca en`False`.
  * `max_tokens`: Un entero que especifica el límite para dividir fragmentos que son demasiado grandes. El valor predeterminado es 512.
  * `tokenizer`: Una cadena que especifica el tokenizador a utilizar al determinar cómo se agrupan los caracteres en un fragmento. Los valores válidos son`openai_tokenizer`,`character_tokenizer`, y`huggingface_tokenizer`. El valor predeterminado es`openai_tokenizer`.
  * `tokenizer_options`: Un árbol con claves de cadena que especifica las opciones para el tokenizador elegido. Por defecto es `{'model_name': 'text-embedding-3-small'}`, que funciona con el tokenizador de OpenAI.
    * Opciones disponibles para `openai_tokenizer`:
      * `model_name`: Acepta todos los modelos soportados por el tokenizador [tiktoken tokenizer](https://github.com/openai/tiktoken) de OpenAI. El valor predeterminado es "text-embedding-3-small"
    * Opciones disponibles para `HuggingFaceTokenizer`:
      * `model_name`: Acepta todos los tokenizadores de huggingface del [huggingface/tokenizers repo](https://github.com/huggingface/tokenizers).
    * `character_tokenizer` no toma ninguna opción.
  * `merge_across_pages`: Un `boolean` que cuando `True` el chunker seleccionado intentará fusionar chunks a través de los límites de página. Por defecto es `True`.
* `output_format`: Una cadena que controla la representación de salida. Por defecto es `json` que produce un array llamado `elements` que contiene los elementos particionados, representados en JSON. Si se establece en `markdown` la respuesta del servicio incluirá en su lugar un campo llamado `markdown` que contiene una cadena que representa todo el documento en formato Markdown.
* `threshold`: Esto representa el umbral para aceptar los cuadros delimitadores predichos por el modelo. Por defecto es `auto`, donde el servicio utiliza un método de procesamiento para encontrar la mejor predicción para cada posible cuadro delimitador. Esta es la configuración recomendada. Sin embargo, esto puede ser anulado especificando un umbral numérico entre 0 y 1. Si especifica un umbral numérico, solo se devolverán los cuadros delimitadores con puntuaciones de confianza superiores al umbral (en lugar de utilizar el método de procesamiento descrito anteriormente). Un valor más bajo incluirá más objetos, pero puede tener superposiciones, mientras que un valor más alto reducirá el número de superposiciones, pero puede perder objetos legítimos. Si establece el umbral manualmente, recomendamos comenzar con un valor de `0.32`.
  Ya sea el específico `string` `auto` o un `float` entre `0.0` y `1.0`, inclusive. Este valor especifica el límite para detectar cuadros delimitadores. Un valor más bajo incluirá más objetos, pero puede tener superposiciones, mientras que un valor más alto reducirá el número de superposiciones, pero puede perder objetos legítimos. El valor predeterminado es `auto` (DocParse elegirá los cuadros delimitadores óptimos).
* `pages_per_call`: Esto solo está disponible cuando se utiliza la función Partition en Sycamore. Esta opción divide el procesamiento de su documento en lotes de páginas, y usted especifica el tamaño de cada lote (número de páginas). Esto es útil cuando se ejecuta OCR en documentos grandes.
* `output_label_options`: Un diccionario de opciones para especificar qué heurística aplicar para forzar ciertas salidas de etiquetas. Si no se especifica esta opción, no se aplica ninguna heurística. Las opciones que admite el diccionario se enumeran a continuación.
  * `promote_title`: Un booleano que especifica si se debe promover un elemento a título si no hay título en la salida.
  * `title_candidate_elements`: Una lista de cadenas que son elementos candidatos para ser promovidos a título.
  * `orientation_correction`: Un valor booleano que especifica si se debe corregir la orientación de las páginas rotadas durante el paso de preprocesamiento.
* `markdown_options`: Un diccionario de opciones para especificar qué incluir en la salida de markdown.
  * `include_pagenum`: Un booleano que especifica si se deben incluir los números de página en la salida de markdown. El valor predeterminado es `False`.
  * `include_headers`: Un booleano que especifica si se deben incluir los encabezados en la salida de markdown. El valor predeterminado es `False`.
  * `include_footers`: Un booleano que especifica si se deben incluir los pies de página en la salida de markdown. El valor predeterminado es `False`.
* `use_ocr` (obsoleto): Un valor booleano que, cuando se establece en `True`, hace que DocParse extraiga texto usando un modelo OCR. Esto es útil cuando el texto no es directamente extraíble del PDF, como cuando el texto es parte de una imagen o cuando el texto está rotado. Cuando se establece en `False`, DocParse extrae el texto incrustado del documento de entrada. El valor predeterminado es `False`.

Aquí hay un ejemplo de cómo puede usar algunas de estas opciones en un comando curl o en código Python con el [Aryn SDK](./aryn_sdk).

<CodeGroup>
  ```bash curl
  export ARYN_API_KEY="PUT API KEY HERE"
  curl -s -N -D headers "https://api.aryn.cloud/v1/document/partition" -H "Authorization: Bearer $ARYN_API_KEY" -F "file=@document.pdf" -F 'options={"text_mode": "standard_ocr", "extract_table_structure": true, "threshold": 0.2}' | tee document.json
  ```

  ```python aryn_sdk.py
  import os
  import json
  from aryn_sdk.partition import partition_file
  os.environ["ARYN_API_KEY"] = "PUT API KEY HERE"
  with open("document.pdf", "rb") as f:
      ans = partition_file(
          file=f,
          text_mode="standard_ocr",
          extract_table_structure=True,
          threshold=0.2
      )
  with open("document.json", "w") as f:
      json.dump(ans, f)
  ```
</CodeGroup>
